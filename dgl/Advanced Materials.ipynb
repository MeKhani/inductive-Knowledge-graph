{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "import torch\n",
    "import numpy as np\n",
    "os.environ['TORCH'] = torch.__version__\n",
    "os.environ['DGLBACKEND'] = \"pytorch\"\n",
    "import dgl\n",
    "import dgl.graphbolt as gb\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import sklearn.metrics\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset is already preprocessed.\n"
     ]
    }
   ],
   "source": [
    "dataset = gb.BuiltinDataset(\"ogbn-arxiv\",root=\"../../../data/datasets\").load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset consists of graph, feature and tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: node_classification. Number of classes: 40\n"
     ]
    }
   ],
   "source": [
    "graph = dataset.graph\n",
    "feature = dataset.feature\n",
    "train_set = dataset.tasks[0].train_set\n",
    "valid_set = dataset.tasks[0].validation_set\n",
    "test_set = dataset.tasks[0].test_set\n",
    "task_name = dataset.tasks[0].metadata[\"name\"]\n",
    "num_classes = dataset.tasks[0].metadata[\"num_classes\"]\n",
    "print(f\"Task: {task_name}. Number of classes: {num_classes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining Neighbor Sampler and Data Loader in DGL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapipe = gb.ItemSampler(train_set, batch_size=1024, shuffle=True)\n",
    "datapipe = datapipe.sample_neighbor(graph, [4, 4])\n",
    "datapipe = datapipe.fetch_feature(feature, node_feature_keys=[\"feat\"])\n",
    "datapipe = datapipe.copy_to(device)\n",
    "train_dataloader = gb.DataLoader(datapipe, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iterate over the data loader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MiniBatch(seeds=tensor([124023,  46807,  54874,  ..., 145854, 125684,  49347]),\n",
      "          sampled_subgraphs=[SampledSubgraphImpl(sampled_csc=CSCFormatBase(indptr=tensor([    0,     4,     8,  ..., 14676, 14680, 14684], dtype=torch.int32),\n",
      "                                                                         indices=tensor([   0, 1024, 3871,  ..., 7848, 3870, 4319], dtype=torch.int32),\n",
      "                                                           ),\n",
      "                                               original_row_node_ids=tensor([124023,  46807,  54874,  ..., 162909, 129411,  65153]),\n",
      "                                               original_edge_ids=tensor([2439621, 2273367,  853857,  ...,  541096, 2316641, 2139748]),\n",
      "                                               original_column_node_ids=tensor([124023,  46807,  54874,  ...,  58554,   6358,   1043]),\n",
      "                            ),\n",
      "                            SampledSubgraphImpl(sampled_csc=CSCFormatBase(indptr=tensor([   0,    4,    8,  ..., 3634, 3638, 3642], dtype=torch.int32),\n",
      "                                                                         indices=tensor([1024,    0, 1025,  ..., 3868, 3869, 3870], dtype=torch.int32),\n",
      "                                                           ),\n",
      "                                               original_row_node_ids=tensor([124023,  46807,  54874,  ...,  58554,   6358,   1043]),\n",
      "                                               original_edge_ids=tensor([2273367, 2439621, 2165767,  ...,  802013,   91311,   12980]),\n",
      "                                               original_column_node_ids=tensor([124023,  46807,  54874,  ..., 145854, 125684,  49347]),\n",
      "                            )],\n",
      "          node_features={'feat': tensor([[-0.0883, -0.1481, -0.1361,  ...,  0.2523, -0.0551, -0.0215],\n",
      "                                [-0.0645,  0.0598, -0.1087,  ...,  0.1092, -0.0709,  0.0601],\n",
      "                                [ 0.0651, -0.0046, -0.2526,  ..., -0.0309,  0.1373, -0.0006],\n",
      "                                ...,\n",
      "                                [-0.0738, -0.0712, -0.2459,  ...,  0.1259,  0.0026, -0.1784],\n",
      "                                [ 0.0021,  0.0805, -0.2701,  ...,  0.0305, -0.0858, -0.1369],\n",
      "                                [ 0.0865,  0.0255, -0.3387,  ...,  0.2130, -0.0082, -0.1046]])},\n",
      "          labels=tensor([ 2,  2, 27,  ..., 19,  4, 34]),\n",
      "          input_nodes=tensor([124023,  46807,  54874,  ..., 162909, 129411,  65153]),\n",
      "          indexes=None,\n",
      "          edge_features=[{},\n",
      "                        {}],\n",
      "          compacted_seeds=None,\n",
      "          blocks=[Block(num_src_nodes=11697, num_dst_nodes=3871, num_edges=14684),\n",
      "                 Block(num_src_nodes=3871, num_dst_nodes=1024, num_edges=3642)],\n",
      "       )\n"
     ]
    }
   ],
   "source": [
    "data = next(iter(train_dataloader))\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " node IDs from MFGs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input nodes tensor([124023,  46807,  54874,  ..., 162909, 129411,  65153]). \n"
     ]
    }
   ],
   "source": [
    "mfgs =data.blocks\n",
    "input_nodes = mfgs[0].srcdata[dgl.NID]\n",
    "print(f\"Input nodes {input_nodes }. \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "defining model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgl.nn import SAGEConv\n",
    "\n",
    "class myModel(nn.Module):\n",
    "    def __init__(self ,in_feat,h_feat,num_classes):\n",
    "        super().__init__()\n",
    "        self.conv1 = SAGEConv(in_feat,h_feat,aggregator_type=\"mean\")\n",
    "        self.conv2 = SAGEConv(h_feat,num_classes,aggregator_type=\"mean\")\n",
    "        self.h_feat = h_feat \n",
    "    def forward(self ,mfgs,x):\n",
    "        h= self.conv1(mfgs[0],x)\n",
    "        h = F.relu(h)\n",
    "        h = self.conv2(mfgs[1],h)\n",
    "        return h \n",
    "in_size = feature.size(\"node\", None, \"feat\")[0]\n",
    "model = myModel(in_size,16,num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define valdiation loader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapipe = gb.ItemSampler(valid_set, batch_size=1024, shuffle=True)\n",
    "datapipe = datapipe.sample_neighbor(graph, [4, 4])\n",
    "datapipe = datapipe.fetch_feature(feature, node_feature_keys=[\"feat\"])\n",
    "datapipe = datapipe.copy_to(device)\n",
    "valid_dataloader = gb.DataLoader(datapipe, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "89it [00:03, 24.58it/s, loss=1.817, acc=0.511]\n",
      "30it [00:00, 39.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Validation Accuracy 0.5140776536125373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import tqdm \n",
    "\n",
    "for epoch in range(100):\n",
    "    model.train()\n",
    "    with tqdm.tqdm(train_dataloader) as tq:\n",
    "        for step , data in enumerate(tq):\n",
    "            x = data.node_features[\"feat\"]\n",
    "            labels = data.labels\n",
    "\n",
    "            predictions= model(data.blocks,x)\n",
    "\n",
    "            loss = F.cross_entropy(predictions,labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            accuracy = sklearn.metrics.accuracy_score(\n",
    "                labels.cpu().numpy(),predictions.argmax(1).detach().cpu().numpy()\n",
    "            )\n",
    "            tq.set_postfix(\n",
    "                 {\"loss\": \"%.03f\" % loss.item(), \"acc\": \"%.03f\" % accuracy},\n",
    "                refresh=False,\n",
    "            )\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    labels = []\n",
    "    with tqdm.tqdm(valid_dataloader) as tq:\n",
    "        for step , data in enumerate(tq):\n",
    "            x = data.node_features[\"feat\"]\n",
    "            labels.append(data.labels.cpu().numpy())\n",
    "            predictions.append(model(data.blocks, x).argmax(1).cpu().numpy())\n",
    "        predictions = np.concatenate(predictions)\n",
    "        labels = np.concatenate(labels)\n",
    "        accuracy = sklearn.metrics.accuracy_score(labels, predictions)\n",
    "        print(\"Epoch {} Validation Accuracy {}\".format(epoch, accuracy))\n",
    "\n",
    "        # Note that this tutorial do not train the whole model to the end.\n",
    "    \n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
