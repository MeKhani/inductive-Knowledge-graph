{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "import torch\n",
    "import numpy as np\n",
    "os.environ['TORCH'] = torch.__version__\n",
    "os.environ['DGLBACKEND'] = \"pytorch\"\n",
    "import dgl\n",
    "import dgl.graphbolt as gb\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import sklearn.metrics\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Link Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading ../../../data/datasets\\cora-seeds.zip from https://data.dgl.ai/dataset/graphbolt/cora-seeds.zip...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f846ee0413ed4dab8c1e2185c1889d9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "../../../data/datasets\\cora-seeds.zip:   0%|          | 0.00/242k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting file to ../../../data/datasets\n",
      "Start to preprocess the on-disk dataset.\n",
      "Finish preprocessing the on-disk dataset.\n"
     ]
    }
   ],
   "source": [
    "dataset = gb.BuiltinDataset(\"cora\",root=\"../../../data/datasets\").load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task name is link_prediction\n"
     ]
    }
   ],
   "source": [
    "graph = dataset.graph\n",
    "features = dataset.feature \n",
    "train_set= dataset.tasks[1].train_set\n",
    "validation_set= dataset.tasks[1].validation_set\n",
    "test_set= dataset.tasks[1].test_set\n",
    "task_name = dataset.tasks[1].metadata[\"name\"]\n",
    "print(f\"task name is {task_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "datapipe = gb.ItemSampler(train_set, batch_size=256, shuffle=True)\n",
    "datapipe = datapipe.sample_uniform_negative(graph, 5)\n",
    "datapipe = datapipe.sample_neighbor(graph, [5, 5, 5])\n",
    "datapipe = datapipe.transform(partial(gb.exclude_seed_edges, include_reverse_edges=True))\n",
    "datapipe = datapipe.fetch_feature(features, node_feature_keys=[\"feat\"])\n",
    "datapipe = datapipe.copy_to(device)\n",
    "train_dataloader = gb.DataLoader(datapipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MiniBatch: MiniBatch(seeds=tensor([[ 156,  817],\n",
      "                        [ 915, 2597],\n",
      "                        [2169,  683],\n",
      "                        ...,\n",
      "                        [ 148,  905],\n",
      "                        [ 148,  279],\n",
      "                        [ 148, 1273]], dtype=torch.int32),\n",
      "          sampled_subgraphs=[SampledSubgraphImpl(sampled_csc=CSCFormatBase(indptr=tensor([   0,    4,    7,  ..., 7643, 7644, 7646], dtype=torch.int32),\n",
      "                                                                         indices=tensor([ 931, 1284,  258,  ..., 2242, 1470, 2249], dtype=torch.int32),\n",
      "                                                           ),\n",
      "                                               original_row_node_ids=tensor([ 156,  817,  915,  ...,  229, 1053, 1559], dtype=torch.int32),\n",
      "                                               original_edge_ids=None,\n",
      "                                               original_column_node_ids=tensor([ 156,  817,  915,  ..., 2621, 2264, 2128], dtype=torch.int32),\n",
      "                            ),\n",
      "                            SampledSubgraphImpl(sampled_csc=CSCFormatBase(indptr=tensor([   0,    4,    7,  ..., 7004, 7008, 7013], dtype=torch.int32),\n",
      "                                                                         indices=tensor([  88, 1285,  258,  ..., 1931, 1815, 2249], dtype=torch.int32),\n",
      "                                                           ),\n",
      "                                               original_row_node_ids=tensor([ 156,  817,  915,  ..., 2621, 2264, 2128], dtype=torch.int32),\n",
      "                                               original_edge_ids=None,\n",
      "                                               original_column_node_ids=tensor([ 156,  817,  915,  ..., 2086, 2129, 1111], dtype=torch.int32),\n",
      "                            ),\n",
      "                            SampledSubgraphImpl(sampled_csc=CSCFormatBase(indptr=tensor([   0,    4,    7,  ..., 3768, 3773, 3778], dtype=torch.int32),\n",
      "                                                                         indices=tensor([  88, 1284,  258,  ..., 2097, 1436, 2250], dtype=torch.int32),\n",
      "                                                           ),\n",
      "                                               original_row_node_ids=tensor([ 156,  817,  915,  ..., 2086, 2129, 1111], dtype=torch.int32),\n",
      "                                               original_edge_ids=None,\n",
      "                                               original_column_node_ids=tensor([ 156,  817,  915,  ..., 2594, 1505, 1273], dtype=torch.int32),\n",
      "                            )],\n",
      "          node_features={'feat': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "                                [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "                                [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "                                ...,\n",
      "                                [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "                                [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "                                [0., 0., 0.,  ..., 0., 0., 0.]])},\n",
      "          labels=tensor([1., 1., 1.,  ..., 0., 0., 0.]),\n",
      "          input_nodes=tensor([ 156,  817,  915,  ...,  229, 1053, 1559], dtype=torch.int32),\n",
      "          indexes=tensor([  0,   1,   2,  ..., 255, 255, 255]),\n",
      "          edge_features=[{},\n",
      "                        {},\n",
      "                        {}],\n",
      "          compacted_seeds=tensor([[   0,    1],\n",
      "                                  [   2,    3],\n",
      "                                  [   4,    5],\n",
      "                                  ...,\n",
      "                                  [ 433,  203],\n",
      "                                  [ 433, 1261],\n",
      "                                  [ 433, 1283]], dtype=torch.int32),\n",
      "          blocks=[Block(num_src_nodes=2583, num_dst_nodes=2510, num_edges=7646),\n",
      "                 Block(num_src_nodes=2510, num_dst_nodes=2251, num_edges=7013),\n",
      "                 Block(num_src_nodes=2251, num_dst_nodes=1284, num_edges=3778)],\n",
      "       )\n"
     ]
    }
   ],
   "source": [
    "data = next(iter(train_dataloader))\n",
    "print(f\"MiniBatch: {data}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining Model for Node Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl.nn as dgln\n",
    "class SAGE(nn.Module):\n",
    "    def __init__(self, in_size,hidden_size):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.layers.append(dgln.SAGEConv(in_size,hidden_size,\"mean\"))\n",
    "        self.layers.append(dgln.SAGEConv(hidden_size,hidden_size,\"mean\"))\n",
    "        self.hidden_size = hidden_size\n",
    "        self.prdictor = nn.Sequential(\n",
    "            nn.Linear(in_size,hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size,1)\n",
    "        )\n",
    "    def froward(self,blocks,x):\n",
    "        hidden_x =x\n",
    "        for layer_idx,(layer,block) in enumerate(zip(self.layers,blocks)):\n",
    "            hidden_x = layer(block,hidden_x)\n",
    "            is_last_layer = layer_idx == len(self.layers)-1\n",
    "            if not is_last_layer:\n",
    "                hidden_x =F.relu(hidden_x)\n",
    "        return hidden_x \n",
    "\n",
    "\n",
    "        \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
